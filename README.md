# ollama-benchmark
LLMs Throughput Benchmark for Ollama

## Installation Steps
```bash
pip3 install -r requirements.txt
```
It's tested on Python 3.9 and above.

## ollama installation with the following models installed
7B model can be run on machines with 8GB of RAM
13B model can be run on machines with 16GB of RAM

```bash
ollama run mistral
ollama run llama2
ollama run llama2:13b
ollama run llava
```

## Reference
[Ollama](https://ollama.ai)